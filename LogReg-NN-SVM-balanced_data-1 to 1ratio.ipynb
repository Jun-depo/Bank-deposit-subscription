{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./bank_additional_full_clean_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.642226</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.196449</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093868</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.642226</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.932543</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  job  marital  education  default  housing  loan  contact  month  \\\n",
       "0  1.642226    0        2          1        0        0     0        0      5   \n",
       "1 -0.196449    1        2          4        0        1     0        0      5   \n",
       "2  0.093868    2        2          2        0        0     0        0      5   \n",
       "3  1.642226    1        2          4        0        0     1        0      5   \n",
       "4  1.932543    2        2          5        0        0     0        0      5   \n",
       "\n",
       "   day_of_week  ...  campaign     pdays  previous  poutcome  emp.var.rate  \\\n",
       "0            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "1            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "2            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "3            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "4            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0        0.804082       0.877437   0.786089     0.401641  0  \n",
       "1        0.804082       0.877437   0.786089     0.401641  0  \n",
       "2        0.804082       0.877437   0.786089     0.401641  0  \n",
       "3        0.804082       0.877437   0.786089     0.401641  0  \n",
       "4        0.804082       0.877437   0.786089     0.401641  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30488, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[df['y']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['y']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24658</th>\n",
       "      <td>0.093868</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.073330</td>\n",
       "      <td>-1.076766</td>\n",
       "      <td>-1.168813</td>\n",
       "      <td>-1.234470</td>\n",
       "      <td>-0.821115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>-0.099677</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191699</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.787777</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16015</th>\n",
       "      <td>0.093868</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913755</td>\n",
       "      <td>-0.135488</td>\n",
       "      <td>0.940077</td>\n",
       "      <td>0.845733</td>\n",
       "      <td>0.895268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>-0.680311</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191699</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913755</td>\n",
       "      <td>0.674250</td>\n",
       "      <td>-0.438010</td>\n",
       "      <td>0.845733</td>\n",
       "      <td>0.895268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13622</th>\n",
       "      <td>0.868047</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.646434</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913755</td>\n",
       "      <td>-0.135488</td>\n",
       "      <td>0.940077</td>\n",
       "      <td>0.847421</td>\n",
       "      <td>0.895268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  job  marital  education  default  housing  loan  contact  \\\n",
       "24658  0.093868    3        2          1        0        1     0        1   \n",
       "2034  -0.099677    3        0          1        0        1     0        0   \n",
       "16015  0.093868    4        2          5        0        0     0        1   \n",
       "8954  -0.680311    2        0          6        0        0     0        1   \n",
       "13622  0.868047    3        2          1        0        0     0        1   \n",
       "\n",
       "       month  day_of_week  ...  campaign     pdays  previous  poutcome  \\\n",
       "24658      5            4  ... -0.559326  0.211884  -0.37161         1   \n",
       "2034       5            4  ... -0.191699  0.211884  -0.37161         1   \n",
       "16015      8            5  ... -0.559326  0.211884  -0.37161         1   \n",
       "8954       7            5  ... -0.191699  0.211884  -0.37161         1   \n",
       "13622      8            2  ...  1.646434  0.211884  -0.37161         1   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "24658     -1.073330       -1.076766      -1.168813  -1.234470    -0.821115  0  \n",
       "2034       0.727466        0.804082       0.877437   0.787777     0.401641  0  \n",
       "16015      0.913755       -0.135488       0.940077   0.845733     0.895268  0  \n",
       "8954       0.913755        0.674250      -0.438010   0.845733     0.895268  0  \n",
       "13622      0.913755       -0.135488       0.940077   0.847421     0.895268  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle(df0, random_state=101).head()\n",
    "# random shuffle class 0 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_rs = shuffle(df0, random_state=101).iloc[0:3859]\n",
    "# pick 10000 class 0 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merg = pd.concat([df1, df0_rs])\n",
    "# mix 10000 class 0 and all class 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merg = shuffle(df_merg, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19728</th>\n",
       "      <td>-0.002904</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.371610</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.073330</td>\n",
       "      <td>-0.765854</td>\n",
       "      <td>-1.356734</td>\n",
       "      <td>-1.129250</td>\n",
       "      <td>-0.821115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29808</th>\n",
       "      <td>0.190640</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191699</td>\n",
       "      <td>-4.719257</td>\n",
       "      <td>5.366854</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.011233</td>\n",
       "      <td>0.860456</td>\n",
       "      <td>0.480715</td>\n",
       "      <td>-1.437595</td>\n",
       "      <td>-2.251434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>-0.970628</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543554</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.371610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913755</td>\n",
       "      <td>0.674250</td>\n",
       "      <td>-0.438010</td>\n",
       "      <td>0.844045</td>\n",
       "      <td>0.895268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28085</th>\n",
       "      <td>2.416405</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>1.541211</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.066872</td>\n",
       "      <td>-1.866005</td>\n",
       "      <td>2.861046</td>\n",
       "      <td>-1.536062</td>\n",
       "      <td>-1.906827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>-0.873856</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175927</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.371610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.790028</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  job  marital  education  default  housing  loan  contact  \\\n",
       "19728 -0.002904    8        2          5        0        0     1        1   \n",
       "29808  0.190640    4        1          6        0        1     0        1   \n",
       "8033  -0.970628    1        0          4        0        1     0        1   \n",
       "28085  2.416405    2        2          4        0        1     0        1   \n",
       "4882  -0.873856    3        0          2        0        1     0        0   \n",
       "\n",
       "       month  day_of_week  ...  campaign     pdays  previous  poutcome  \\\n",
       "19728      4            2  ... -0.559326  0.211884 -0.371610         1   \n",
       "29808      8            5  ... -0.191699 -4.719257  5.366854         2   \n",
       "8033       7            1  ...  0.543554  0.211884 -0.371610         1   \n",
       "28085     10            5  ... -0.559326  0.211884  1.541211         0   \n",
       "4882       5            5  ...  0.175927  0.211884 -0.371610         1   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "19728     -1.073330       -0.765854      -1.356734  -1.129250    -0.821115  0  \n",
       "29808     -1.011233        0.860456       0.480715  -1.437595    -2.251434  1  \n",
       "8033       0.913755        0.674250      -0.438010   0.844045     0.895268  0  \n",
       "28085     -2.066872       -1.866005       2.861046  -1.536062    -1.906827  1  \n",
       "4882       0.727466        0.804082       0.877437   0.790028     0.401641  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7718"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "y = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 30488\n",
      "Number of features: 19\n",
      "Number of categorical features: 10\n",
      "Number of numerical features: 9\n"
     ]
    }
   ],
   "source": [
    "categorical_columns_subset = [\n",
    "    'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'\n",
    "]\n",
    "\n",
    "numerical_columns_subset = [\n",
    "    'duration', 'campaign', 'pdays',\n",
    "    'previous', 'emp.var.rate', 'cons.price.idx', \n",
    "    'cons.conf.idx', 'euribor3m', 'nr.employed'\n",
    "]\n",
    "\n",
    "X = X[categorical_columns_subset + numerical_columns_subset]\n",
    "X[categorical_columns_subset] = X[categorical_columns_subset].astype(\"category\")\n",
    "\n",
    "n_categorical_features = X.select_dtypes(include=\"category\").shape[1]\n",
    "n_numerical_features = X.select_dtypes(include=\"number\").shape[1]\n",
    "\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of categorical features: {n_categorical_features}\")\n",
    "print(f\"Number of numerical features: {n_numerical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "one_hot_encoder = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n",
    "        make_column_selector(dtype_include=\"category\"),\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr1 = make_pipeline(one_hot_encoder,\n",
    "                        LogisticRegression(C=1.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr2 = make_pipeline(one_hot_encoder,\n",
    "                        LogisticRegression(C=3.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr3 = make_pipeline(one_hot_encoder,\n",
    "                        LogisticRegression(C=10.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr4 = make_pipeline(one_hot_encoder,\n",
    "                        LogisticRegression(C=30.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr5 = make_pipeline(one_hot_encoder,\n",
    "                        LogisticRegression(C=100.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr6 = make_pipeline(one_hot_encoder,\n",
    "                        LogisticRegression(C=300.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr7 = make_pipeline(one_hot_encoder,\n",
    "                        LogisticRegression(C=1000.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr8 = make_pipeline(one_hot_encoder,\n",
    "                        LogisticRegression(C=3000.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lst = [clf_lr1, clf_lr2, clf_lr3,clf_lr4,clf_lr5, clf_lr6, clf_lr7, clf_lr8]\n",
    "cc_lst = [1, 3, 10, 30, 100, 300, 1000, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression classifier 1, C=1\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72916\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 2, C=3\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72974\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 3, C=10\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72999\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 4, C=30\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72958\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 5, C=100\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72958\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 6, C=300\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72958\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 7, C=1000\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72958\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 8, C=3000\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72958\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "The best Logistic regression classifier is classifier 3 with Micro-Average F1_score 0.72999\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(lr_lst)):\n",
    "    print(f\"Logistic regression classifier {i+1}, C={cc_lst[i]}\")\n",
    "    #print(\"Classification report on trainng data: \\n\", classification_report(y_train, rf_lst[i].predict(X_train)))\n",
    "    cl_rep = classification_report(y_test, lr_lst[i].predict(X_test), digits=4, output_dict=True)\n",
    "    f1_sc = cl_rep['macro avg']['f1-score']\n",
    "    \n",
    "    if f1_sc > best_f1:\n",
    "        best_f1 = f1_sc\n",
    "        best_idx = i+1\n",
    "    print('Classification report on test data:')\n",
    "    print(f\"f1-score of macro average: {f1_sc:.5f}\\n\", )\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"\\nThe best Logistic regression classifier is classifier {best_idx} with Micro-Average F1_score {best_f1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf_lr3, \"best_Logistic regression_model_one_hot_C10_balanced_data.sav\")\n",
    "clf_load = joblib.load(\"best_Logistic regression_model_one_hot_C10_balanced_data.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9225436289744203,\n",
       "  'recall': 0.9646294213223348,\n",
       "  'f1-score': 0.9431172481212197,\n",
       "  'support': 8001},\n",
       " '1': {'precision': 0.6376440460947503,\n",
       "  'recall': 0.43455497382198954,\n",
       "  'f1-score': 0.5168655941878567,\n",
       "  'support': 1146},\n",
       " 'accuracy': 0.8982179949710287,\n",
       " 'macro avg': {'precision': 0.7800938375345854,\n",
       "  'recall': 0.6995921975721622,\n",
       "  'f1-score': 0.7299914211545382,\n",
       "  'support': 9147},\n",
       " 'weighted avg': {'precision': 0.8868494208209162,\n",
       "  'recall': 0.8982179949710287,\n",
       "  'f1-score': 0.8897134659623005,\n",
       "  'support': 9147}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, clf_load.predict(X_test), output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression classifier 1, C=1\n",
      "roc_auc_score on test data: 0.92870\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 2, C=3\n",
      "roc_auc_score on test data: 0.92867\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 3, C=10\n",
      "roc_auc_score on test data: 0.92865\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 4, C=30\n",
      "roc_auc_score on test data: 0.92864\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 5, C=100\n",
      "roc_auc_score on test data: 0.92864\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 6, C=300\n",
      "roc_auc_score on test data: 0.92864\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 7, C=1000\n",
      "roc_auc_score on test data: 0.92864\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Logistic regression classifier 8, C=3000\n",
      "roc_auc_score on test data: 0.92864\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "The best Logistic regression roc_auc_score 0.92870 is from classifier 1 \n"
     ]
    }
   ],
   "source": [
    "best_auc = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(lr_lst)):\n",
    "    print(f\"Logistic regression classifier {i+1}, C={cc_lst[i]}\")\n",
    "    \n",
    "    auc_sc = roc_auc_score(y_test, lr_lst[i].predict_proba(X_test)[:,1])\n",
    "    \n",
    "    if auc_sc > best_auc:\n",
    "        best_auc = auc_sc\n",
    "        best_idx = i+1\n",
    "    \n",
    "    print(f\"roc_auc_score on test data: {auc_sc:.5f}\\n\")\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"The best Logistic regression roc_auc_score {best_auc:.5f} is from classifier {best_idx} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All logistic regression models performed almost identcally. Model 4 are slightly better. Not as good as Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn1 = make_pipeline(one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.001, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn2 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.003, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn3 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.01, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn4 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.03, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn5 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.1, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn6 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.3, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn7 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,4), alpha=1, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn8 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,4), alpha=3, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn9 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,8, 4), alpha=0.001, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn10 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,8,4), alpha=0.003, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn11 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,8,4), alpha=0.01, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn12 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,8,4), alpha=0.03, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn13 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,8,4), alpha=0.1, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn14 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,8,4), alpha=0.3, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn15 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,8,4), alpha=1.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn16 =make_pipeline( one_hot_encoder,\n",
    "                       MLPClassifier(hidden_layer_sizes=(20,8,4), alpha=3.0, max_iter=600)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_lst = [clf_nn1, clf_nn2, clf_nn3, clf_nn4, clf_nn5, clf_nn6, clf_nn7, clf_nn8, clf_nn9, clf_nn10, clf_nn11, \n",
    "          clf_nn12, clf_nn13, clf_nn14, clf_nn15, clf_nn16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classifier 1\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.76833\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 2\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.75980\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 3\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.75564\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 4\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.77085\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 5\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.77819\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 6\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.76413\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 7\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.76525\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 8\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.75224\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 9\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.73669\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 10\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.75716\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 11\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.77702\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 12\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.76627\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 13\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.76942\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 14\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.77462\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 15\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.77104\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 16\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.75003\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "The best Neural network classifier is classifier 5 with Micro-Average F1_score 0.77819\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(nn_lst)):\n",
    "    print(f\"Neural network classifier {i+1}\")\n",
    "    #print(\"Classification report on trainng data: \\n\", classification_report(y_train, rf_lst[i].predict(X_train)))\n",
    "    cl_rep = classification_report(y_test, nn_lst[i].predict(X_test), digits=4, output_dict=True)\n",
    "    f1_sc = cl_rep['macro avg']['f1-score']\n",
    "    \n",
    "    if f1_sc > best_f1:\n",
    "        best_f1 = f1_sc\n",
    "        best_idx = i+1\n",
    "    print('Classification report on test data:')\n",
    "    print(f\"f1-score of macro average: {f1_sc:.5f}\\n\", )\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"\\nThe best Neural network classifier is classifier {best_idx} with Micro-Average F1_score {best_f1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f11ae4d1b20>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.3, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf_nn6, \"best_neural network_model_one_hot_balanced_data.sav\")\n",
    "clf_load = joblib.load(\"best_neural network_model_one_hot_balanced_data.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9358832904254015,\n",
       "  'recall': 0.9541307336582927,\n",
       "  'f1-score': 0.9449189256096051,\n",
       "  'support': 8001},\n",
       " '1': {'precision': 0.6292929292929293,\n",
       "  'recall': 0.543630017452007,\n",
       "  'f1-score': 0.5833333333333334,\n",
       "  'support': 1146},\n",
       " 'accuracy': 0.9027003389089319,\n",
       " 'macro avg': {'precision': 0.7825881098591654,\n",
       "  'recall': 0.7488803755551499,\n",
       "  'f1-score': 0.7641261294714692,\n",
       "  'support': 9147},\n",
       " 'weighted avg': {'precision': 0.8974715101851246,\n",
       "  'recall': 0.9027003389089319,\n",
       "  'f1-score': 0.8996169589813545,\n",
       "  'support': 9147}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, clf_load.predict(X_test), output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model 6 performed the best based on macro average f1-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classifier 1\n",
      "roc_auc_score on test data: 0.93167\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 2\n",
      "roc_auc_score on test data: 0.92982\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 3\n",
      "roc_auc_score on test data: 0.92772\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 4\n",
      "roc_auc_score on test data: 0.93221\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 5\n",
      "roc_auc_score on test data: 0.93586\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 6\n",
      "roc_auc_score on test data: 0.93740\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 7\n",
      "roc_auc_score on test data: 0.93497\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 8\n",
      "roc_auc_score on test data: 0.92997\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 9\n",
      "roc_auc_score on test data: 0.91827\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 10\n",
      "roc_auc_score on test data: 0.92712\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 11\n",
      "roc_auc_score on test data: 0.93011\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 12\n",
      "roc_auc_score on test data: 0.92505\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 13\n",
      "roc_auc_score on test data: 0.92957\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 14\n",
      "roc_auc_score on test data: 0.93647\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 15\n",
      "roc_auc_score on test data: 0.93533\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural network classifier 16\n",
      "roc_auc_score on test data: 0.92999\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "The best Neural network roc_auc_score 0.93740 is from classifier 6 \n"
     ]
    }
   ],
   "source": [
    "best_auc = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(nn_lst)):\n",
    "    print(f\"Neural network classifier {i+1}\")\n",
    "    \n",
    "    auc_sc = roc_auc_score(y_test, nn_lst[i].predict_proba(X_test)[:,1])\n",
    "    \n",
    "    if auc_sc > best_auc:\n",
    "        best_auc = auc_sc\n",
    "        best_idx = i+1\n",
    "    \n",
    "    print(f\"roc_auc_score on test data: {auc_sc:.5f}\\n\")\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"The best Neural network roc_auc_score {best_auc:.5f} is from classifier {best_idx} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network model 15 has the best roc_auc_score on the cross-validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc1 = make_pipeline(one_hot_encoder, SVC(C=1.0, probability=True)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc2 = make_pipeline(one_hot_encoder, SVC(C=3.0, probability=True)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc3 = make_pipeline(one_hot_encoder, SVC(C=10.0, probability=True)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc4 = make_pipeline(one_hot_encoder, SVC(C=30.0, probability=True)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc5 = make_pipeline(one_hot_encoder, SVC(C=100.0, probability=True)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc6 = make_pipeline(one_hot_encoder, SVC(C=300.0, probability=True)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc7 = make_pipeline(one_hot_encoder, SVC(C=1000.0, probability=True)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_lst = [clf_svc1, clf_svc2, clf_svc3, clf_svc4, clf_svc5, clf_svc6, clf_svc7]\n",
    "svc_c = [1, 3, 10, 30, 100, 300, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier 1, C=1\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.73051\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 2, C=3\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.74330\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 3, C=10\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.73836\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 4, C=30\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72930\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 5, C=100\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72401\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 6, C=300\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.72209\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 7, C=1000\n",
      "Classification report on test data:\n",
      "f1-score of macro average: 0.71863\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "The best SVM classifier is classifier 2 with Micro-Average F1_score 0.74330\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(svc_lst)):\n",
    "    print(f\"SVM classifier {i+1}, C={svc_c[i]}\")\n",
    "    #print(\"Classification report on trainng data: \\n\", classification_report(y_train, rf_lst[i].predict(X_train)))\n",
    "    cl_rep = classification_report(y_test, svc_lst[i].predict(X_test), digits=4, output_dict=True)\n",
    "    f1_sc = cl_rep['macro avg']['f1-score']\n",
    "    \n",
    "    if f1_sc > best_f1:\n",
    "        best_f1 = f1_sc\n",
    "        best_idx = i+1\n",
    "    print('Classification report on test data:')\n",
    "    print(f\"f1-score of macro average: {f1_sc:.5f}\\n\", )\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"\\nThe best SVM classifier is classifier {best_idx} with Micro-Average F1_score {best_f1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier 1, C=1\n",
      "roc_auc_score on test data: 0.90488\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 2, C=3\n",
      "roc_auc_score on test data: 0.91379\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 3, C=10\n",
      "roc_auc_score on test data: 0.91276\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 4, C=30\n",
      "roc_auc_score on test data: 0.90753\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 5, C=100\n",
      "roc_auc_score on test data: 0.89756\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 6, C=300\n",
      "roc_auc_score on test data: 0.89241\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "SVM classifier 7, C=1000\n",
      "roc_auc_score on test data: 0.88972\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "The best SVM roc_auc_score 0.91379 is from classifier 2 \n"
     ]
    }
   ],
   "source": [
    "best_auc = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(svc_lst)):\n",
    "    print(f\"SVM classifier {i+1}, C={svc_c[i]}\")    \n",
    "    auc_sc = roc_auc_score(y_test, svc_lst[i].predict_proba(X_test)[:,1])    \n",
    "    if auc_sc > best_auc:\n",
    "        best_auc = auc_sc\n",
    "        best_idx = i+1\n",
    "    \n",
    "    print(f\"roc_auc_score on test data: {auc_sc:.5f}\\n\")\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"The best SVM roc_auc_score {best_auc:.5f} is from classifier {best_idx} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf_svc2, \"best_SVM_model_one_hot_C3_balanced_data.sav\")\n",
    "clf_load = joblib.load(\"best_SVM_model_one_hot_C3_balanced_data.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC model 2 (C=3) is the best among the SVC models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.05, step=0.02),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 30, 210, step=30),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12, step=1),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 120, step=20),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=20),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=20),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 4.0, step=1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.25, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.25, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "#     cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "#     cv_scores = np.empty(5)\n",
    "#     for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "#         X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = lgbm.LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=\"binary_logloss\",\n",
    "        early_stopping_rounds=100,\n",
    "        callbacks=[\n",
    "            LightGBMPruningCallback(trial, \"binary_logloss\")\n",
    "        ],  # Add a pruning callback\n",
    "    )\n",
    "    preds = model.predict_proba(X_test)\n",
    "    cv_scores = log_loss(y_test, preds)\n",
    "    mean_loss = np.mean(cv_scores)\n",
    "    print(f\"mean_loss {mean_loss:.5f}\")\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X, y)\n",
    "study.optimize(func, n_trials=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
