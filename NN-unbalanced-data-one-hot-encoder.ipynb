{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori = pd.read_csv(\"bank-additional/bank-additional-full.csv\",  sep=';')\n",
    "df_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.642226</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.196449</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093868</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.642226</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.932543</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  job  marital  education  default  housing  loan  contact  month  \\\n",
       "0  1.642226    0        2          1        0        0     0        0      5   \n",
       "1 -0.196449    1        2          4        0        1     0        0      5   \n",
       "2  0.093868    2        2          2        0        0     0        0      5   \n",
       "3  1.642226    1        2          4        0        0     1        0      5   \n",
       "4  1.932543    2        2          5        0        0     0        0      5   \n",
       "\n",
       "   day_of_week  ...  campaign     pdays  previous  poutcome  emp.var.rate  \\\n",
       "0            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "1            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "2            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "3            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "4            1  ... -0.559326  0.211884  -0.37161         1      0.727466   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0        0.804082       0.877437   0.786089     0.401641  0  \n",
       "1        0.804082       0.877437   0.786089     0.401641  0  \n",
       "2        0.804082       0.877437   0.786089     0.401641  0  \n",
       "3        0.804082       0.877437   0.786089     0.401641  0  \n",
       "4        0.804082       0.877437   0.786089     0.401641  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('bank_additional_full_clean_normalized.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "y = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.642226</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.196449</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.127941</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093868</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.414513</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.642226</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181556</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.932543</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.460365</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>0.211884</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  job  marital  education  default  housing  loan  contact  month  \\\n",
       "0  1.642226    0        2          1        0        0     0        0      5   \n",
       "1 -0.196449    1        2          4        0        1     0        0      5   \n",
       "2  0.093868    2        2          2        0        0     0        0      5   \n",
       "3  1.642226    1        2          4        0        0     1        0      5   \n",
       "4  1.932543    2        2          5        0        0     0        0      5   \n",
       "\n",
       "   day_of_week  duration  campaign     pdays  previous  poutcome  \\\n",
       "0            1  0.005792 -0.559326  0.211884  -0.37161         1   \n",
       "1            1 -0.127941 -0.559326  0.211884  -0.37161         1   \n",
       "2            1 -0.414513 -0.559326  0.211884  -0.37161         1   \n",
       "3            1  0.181556 -0.559326  0.211884  -0.37161         1   \n",
       "4            1 -0.460365 -0.559326  0.211884  -0.37161         1   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0      0.727466        0.804082       0.877437   0.786089     0.401641  \n",
       "1      0.727466        0.804082       0.877437   0.786089     0.401641  \n",
       "2      0.727466        0.804082       0.877437   0.786089     0.401641  \n",
       "3      0.727466        0.804082       0.877437   0.786089     0.401641  \n",
       "4      0.727466        0.804082       0.877437   0.786089     0.401641  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2118836362185938, -4.749052297919588)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.pdays.max(), X.pdays.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv, X_test, y_cv, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 30488\n",
      "Number of features: 19\n",
      "Number of categorical features: 10\n",
      "Number of numerical features: 9\n"
     ]
    }
   ],
   "source": [
    "categorical_columns_subset = [\n",
    "    'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'\n",
    "]\n",
    "\n",
    "numerical_columns_subset = [\n",
    "    'duration', 'campaign', 'pdays',\n",
    "    'previous', 'emp.var.rate', 'cons.price.idx', \n",
    "    'cons.conf.idx', 'euribor3m', 'nr.employed'\n",
    "]\n",
    "\n",
    "X = X[categorical_columns_subset + numerical_columns_subset]\n",
    "X[categorical_columns_subset] = X[categorical_columns_subset].astype(\"category\")\n",
    "\n",
    "n_categorical_features = X.select_dtypes(include=\"category\").shape[1]\n",
    "n_numerical_features = X.select_dtypes(include=\"number\").shape[1]\n",
    "\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of categorical features: {n_categorical_features}\")\n",
    "print(f\"Number of numerical features: {n_numerical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "one_hot_encoder = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n",
    "        make_column_selector(dtype_include=\"category\"),\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.001, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn1 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.001, max_iter=600)\n",
    ")\n",
    "clf_nn1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.003, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn2 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.003, max_iter=600)\n",
    ")\n",
    "clf_nn2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.01, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn3 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.01, max_iter=600)\n",
    ")\n",
    "clf_nn3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.03, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn4 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.03, max_iter=600)\n",
    ")\n",
    "clf_nn4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.1, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn5 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.1, max_iter=600)\n",
    ")\n",
    "clf_nn5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.3, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn6 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(20,4), alpha=0.3, max_iter=600)\n",
    ")\n",
    "clf_nn6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=1, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn7 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(20,4), alpha=1, max_iter=600)\n",
    ")\n",
    "clf_nn7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=3, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn8 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(20,4), alpha=3, max_iter=600)\n",
    ")\n",
    "clf_nn8.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.001, hidden_layer_sizes=(16, 8, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn9 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(16,8,4), alpha=0.001, max_iter=600)\n",
    ")\n",
    "clf_nn9.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.003, hidden_layer_sizes=(16, 8, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn10 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(16,8,4), alpha=0.003, max_iter=600)\n",
    ")\n",
    "clf_nn10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.01, hidden_layer_sizes=(16, 8, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn11 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(16,8,4), alpha=0.01, max_iter=600)\n",
    ")\n",
    "clf_nn11.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.03, hidden_layer_sizes=(16, 8, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn12 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(16,8,4), alpha=0.03, max_iter=600)\n",
    ")\n",
    "clf_nn12.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.1, hidden_layer_sizes=(16, 8, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn13 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(16,8,4), alpha=0.1, max_iter=600)\n",
    ")\n",
    "clf_nn13.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.3, hidden_layer_sizes=(16, 8, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn14 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(16,8,4), alpha=0.3, max_iter=600)\n",
    ")\n",
    "clf_nn14.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=1, hidden_layer_sizes=(16, 8, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn15 = make_pipeline(\n",
    "    one_hot_encoder, MLPClassifier(hidden_layer_sizes=(16,8,4), alpha=1, max_iter=600)\n",
    ")\n",
    "clf_nn15.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_lst = [clf_nn1, clf_nn2, clf_nn3, clf_nn4, clf_nn5, clf_nn6, clf_nn7, clf_nn8, clf_nn9, clf_nn10, clf_nn11, \n",
    "          clf_nn12, clf_nn13, clf_nn14, clf_nn15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nn_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network model  1 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7760\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  2 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7752\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  3 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7617\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  4 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7778\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  5 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7876\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  6 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7678\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  7 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7699\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  8 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7536\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  9 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7550\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  10 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7684\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  11 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7667\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  12 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7698\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  13 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7681\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  14 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7786\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  15 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on cross-validation data:\n",
      "f1-score of macro average: 0.7450\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "The best neural network classifier is classifier 5 with Micro-Average F1_score 0.7875905610910476\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(nn_lst)):\n",
    "    print(\"Neural Network model \", i+1, \n",
    "          \"\\nClassification report on trainng data\\n\",) \n",
    "          #classification_report(y_train, nn_lst[i].predict(X_train)))\n",
    "    cl_rep = classification_report(y_cv, nn_lst[i].predict(X_cv), output_dict=True)\n",
    "    f1_sc = cl_rep['macro avg']['f1-score']\n",
    "    \n",
    "    if f1_sc > best_f1:\n",
    "        best_f1 = f1_sc\n",
    "        best_idx = i+1\n",
    "    print('Classification report on cross-validation data:')\n",
    "    print(f\"f1-score of macro average: {f1_sc:.4f}\\n\")\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"\\nThe best neural network classifier is classifier {best_idx} with Micro-Average F1_score {best_f1}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network model  1 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7501\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  2 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7611\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  3 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7469\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  4 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7670\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  5 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7768\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  6 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7565\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  7 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7638\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  8 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7524\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  9 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7510\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  10 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7606\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  11 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7552\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  12 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7627\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  13 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7523\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  14 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7627\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Neural Network model  15 \n",
      "Classification report on trainng data\n",
      "\n",
      "Classification report on Test data:\n",
      "f1-score of macro average: 0.7433\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "The best neural network classifier is classifier 5 with Micro-Average F1_score 0.7767775891179305 on test data\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(nn_lst)):\n",
    "    print(\"Neural Network model \", i+1, \n",
    "          \"\\nClassification report on trainng data\\n\",) \n",
    "          #classification_report(y_train, nn_lst[i].predict(X_train)))\n",
    "    cl_rep = classification_report(y_test, nn_lst[i].predict(X_test), output_dict=True)\n",
    "    f1_sc = cl_rep['macro avg']['f1-score']\n",
    "    \n",
    "    if f1_sc > best_f1:\n",
    "        best_f1 = f1_sc\n",
    "        best_idx = i+1\n",
    "    print('Classification report on Test data:')\n",
    "    print(f\"f1-score of macro average: {f1_sc:.4f}\\n\")\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"\\nThe best neural network classifier is classifier {best_idx} with Micro-Average F1_score {best_f1} on test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd5405abd00>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.1, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network model 1\n",
      "roc_auc_score on cross-validation data 0.9369\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 2\n",
      "roc_auc_score on cross-validation data 0.9360\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 3\n",
      "roc_auc_score on cross-validation data 0.9379\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 4\n",
      "roc_auc_score on cross-validation data 0.9367\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 5\n",
      "roc_auc_score on cross-validation data 0.9387\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 6\n",
      "roc_auc_score on cross-validation data 0.9372\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 7\n",
      "roc_auc_score on cross-validation data 0.9316\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 8\n",
      "roc_auc_score on cross-validation data 0.9252\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 9\n",
      "roc_auc_score on cross-validation data 0.9345\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 10\n",
      "roc_auc_score on cross-validation data 0.9348\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 11\n",
      "roc_auc_score on cross-validation data 0.9377\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 12\n",
      "roc_auc_score on cross-validation data 0.9351\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 13\n",
      "roc_auc_score on cross-validation data 0.9387\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 14\n",
      "roc_auc_score on cross-validation data 0.9394\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 15\n",
      "roc_auc_score on cross-validation data 0.9337\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "The best Neural Network classifier is classifier 14 with roc_auc_score 0.9394\n"
     ]
    }
   ],
   "source": [
    "best_auc = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(nn_lst)):\n",
    "    print(\"\\nNeural Network model\", i+1)\n",
    "    auc_sc = roc_auc_score(y_cv, nn_lst[i].predict_proba(X_cv)[:, 1])\n",
    "    \n",
    "    if auc_sc > best_auc:\n",
    "        best_auc = auc_sc\n",
    "        best_idx = i+1\n",
    "    \n",
    "    print(f\"roc_auc_score on cross-validation data {auc_sc:.4f}\\n\")\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"The best Neural Network classifier is classifier {best_idx} with roc_auc_score {best_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network model 1\n",
      "roc_auc_score on test data 0.9297\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 2\n",
      "roc_auc_score on test data 0.9339\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 3\n",
      "roc_auc_score on test data 0.9350\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 4\n",
      "roc_auc_score on test data 0.9338\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 5\n",
      "roc_auc_score on test data 0.9335\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 6\n",
      "roc_auc_score on test data 0.9338\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 7\n",
      "roc_auc_score on test data 0.9285\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 8\n",
      "roc_auc_score on test data 0.9220\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 9\n",
      "roc_auc_score on test data 0.9300\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 10\n",
      "roc_auc_score on test data 0.9312\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 11\n",
      "roc_auc_score on test data 0.9347\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 12\n",
      "roc_auc_score on test data 0.9326\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 13\n",
      "roc_auc_score on test data 0.9346\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 14\n",
      "roc_auc_score on test data 0.9354\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Neural Network model 15\n",
      "roc_auc_score on test data 0.9312\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "The best Neural Network classifier is classifier 14 with roc_auc_score 0.9354 on test data\n"
     ]
    }
   ],
   "source": [
    "best_auc = 0\n",
    "best_idx = 999\n",
    "\n",
    "for i in range(len(nn_lst)):\n",
    "    print(\"\\nNeural Network model\", i+1)\n",
    "    auc_sc = roc_auc_score(y_test, nn_lst[i].predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    if auc_sc > best_auc:\n",
    "        best_auc = auc_sc\n",
    "        best_idx = i+1\n",
    "    \n",
    "    print(f\"roc_auc_score on test data {auc_sc:.4f}\\n\")\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    \n",
    "print(f\"The best Neural Network classifier is classifier {best_idx} with roc_auc_score {best_auc:.4f} on test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_neural_network_model_one_hot_classifier5.sav']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf_nn5, \"best_neural_network_model_one_hot_classifier5.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_load = joblib.load(\"best_neural_network_model_one_hot_classifier5.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd540619910>)])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.1, hidden_layer_sizes=(20, 4),\n",
       "                               max_iter=600))])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9533826037521319,\n",
       "  'recall': 0.9382693024990675,\n",
       "  'f1-score': 0.9457655794717549,\n",
       "  'support': 5362},\n",
       " '1': {'precision': 0.5968331303288672,\n",
       "  'recall': 0.6657608695652174,\n",
       "  'f1-score': 0.6294155427103404,\n",
       "  'support': 736},\n",
       " 'accuracy': 0.9053788127254838,\n",
       " 'macro avg': {'precision': 0.7751078670404996,\n",
       "  'recall': 0.8020150860321424,\n",
       "  'f1-score': 0.7875905610910476,\n",
       "  'support': 6098},\n",
       " 'weighted avg': {'precision': 0.9103487545491927,\n",
       "  'recall': 0.9053788127254838,\n",
       "  'f1-score': 0.907583613736038,\n",
       "  'support': 6098}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_cv, clf_load.predict(X_cv), output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best neural network classifier is classifier 5 with Micro-Average F1_score 0.7875905610910476 on cv data\n",
    "\n",
    "### The best neural network classifier is classifier 5 with Micro-Average F1_score 0.7767775891179305 on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch18",
   "language": "python",
   "name": "torch18"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
